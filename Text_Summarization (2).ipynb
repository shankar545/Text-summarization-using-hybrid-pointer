{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "import nltk\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Specify the directory path\n",
        "directory_path = '/content/drive/My Drive/'\n",
        "\n",
        "\n",
        "# Specify the path to the .tgz file\n",
        "file_path = '/content/drive/My Drive/cnn_stories.tgz'\n",
        "\n",
        "# Extract the contents of the .tgz file\n",
        "with tarfile.open(file_path, 'r:gz') as tar:\n",
        "    tar.extractall('/content/data/')\n",
        "\n",
        "# List of file names\n",
        "file_names = [\n",
        "    '8278100e57ce63728df109f76b9888e7a918ad90.story',\n",
        "    '827811c8e01692a37b10247f3a3cd9ebc1ece71b.story',\n",
        "    # Add more file names here\n",
        "]\n",
        "\n",
        "# Split the data\n",
        "train_files, test_files = train_test_split(file_names, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the number of files in each set\n",
        "print(\"Number of training files:\", len(train_files))\n",
        "print(\"Number of testing files:\", len(test_files))\n",
        "\n",
        "# Preprocessing functions\n",
        "def preprocess_content(content):\n",
        "    # Tokenize the content using NLTK\n",
        "    tokens = nltk.word_tokenize(content)\n",
        "\n",
        "    # Convert tokens to numerical representation using a tokenizer\n",
        "    sequences = tokenizer.texts_to_sequences([tokens])\n"
      ],
      "metadata": {
        "id": "oTeSsa0KORsg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08c74087-e539-44ac-e9f8-e625136b4224"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Number of training files: 1\n",
            "Number of testing files: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SX8lNm49QxFW"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Input,Activation,Dot\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for file_name in test_files:\n",
        "    file_path = \"/content/data/cnn/stories/\" + file_name\n",
        "\n",
        "    with open(file_path, \"r\") as file:\n",
        "        content = file.read()\n",
        "\n",
        "    # Process the content as needed\n",
        "    print(\"File:\", file_name)\n",
        "    print(\"Content:\", content)\n",
        "    print(\"----------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jV0rcm16UJP_",
        "outputId": "aaee2fee-1580-43a7-ff1d-6b32217f2ad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File: 827811c8e01692a37b10247f3a3cd9ebc1ece71b.story\n",
            "Content: Los Angeles (CNN) -- Buddy Holly finally got his star on Hollywood's Walk of Fame on Wednesday, which would have been the singer-songwriter's 75th birthday.\n",
            "\n",
            "\"It's never too late when you get a fantastic thing to happen,\" his widow, Maria Elena Holly, told CNN after unveiling the star on the sidewalk along Vine Street at the entrance to the historic Capitol Records building.\n",
            "\n",
            "Holly was just 22 when he was killed in a plane crash, along with musicians Ritchie Valens and J.P. \"The Big Bopper\" Richardson.\n",
            "\n",
            "\"I'm saying now, my dear Buddy, you loved to go to the movies. You told me that one of your dreams was to write scores for movies and make your mark in Hollywood,\" his widow said during the ceremony. \"Well, my dear, half of your dream unfortunately did not come true, but the other half did come true with a beautiful star on the Hollywood Walk of Fame.\"\n",
            "\n",
            "Actor Gary Busey, who channeled Holly's voice and character in the 1978 movie \"The Buddy Holly Story,\" attended the dedication.\n",
            "\n",
            "\"He's here right now,\" Busey said. \"I feel his spirit in the air. It's beautiful.\"\n",
            "\n",
            "What would Holly be doing now if he were still alive?\n",
            "\n",
            "\"Anything he wanted to,\" Busey said. \"Scoring movies, helping people in different countries who are in trouble, like writing a song for them and taking it over there and singing it to them.\"\n",
            "\n",
            "Busey is working with T Bone Burnett on an album of Holly songs, which he said he would also perform in a tour.\n",
            "\n",
            "The Hollywood star ceremony was timed to coincide with this week's release of \"Listen to Me: Buddy Holly,\" a tribute album of his songs performed by 16 artists, including Ringo Starr, Stevie Nick, Brian Wilson, Jackson Browne, Chris Isaak, Linda Ronstadt and Lyle Lovett.\n",
            "\n",
            "Phil Everly of the Everly Brothers, a contemporary of Holly, also attended the dedication.\n",
            "\n",
            "@highlight\n",
            "\n",
            "Holly's star is on Vine at the Capitol Records building\n",
            "\n",
            "@highlight\n",
            "\n",
            "His dream was to make his mark on Hollywood, Holly's widow says\n",
            "\n",
            "@highlight\n",
            "\n",
            "Gary Busey, who played Holly in a film, feels his \"spirit in the air\"\n",
            "\n",
            "@highlight\n",
            "\n",
            "The dedication coincides with the release of a tribute album\n",
            "----------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bahdanau Attention is the function based on the formula given in the abstract that executed successfully"
      ],
      "metadata": {
        "id": "haArA_RwiYbS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, attention_units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W_base_h = Dense(attention_units)\n",
        "        self.W_base_s = Dense(attention_units)\n",
        "        self.V = Dense(1)\n",
        "\n",
        "    def call(self, h, s):\n",
        "        # h: encoder hidden states (shape: batch_size x max_sequence_length x encoder_units)\n",
        "        # s: decoder state (shape: batch_size x decoder_units)\n",
        "\n",
        "        # Expand dimensions of s to match h\n",
        "        s = tf.expand_dims(s, axis=1)\n",
        "\n",
        "        # Calculate attention scores\n",
        "        e = self.V(tf.nn.tanh(self.W_base_h(h) + self.W_base_s(s)))\n",
        "\n",
        "        # Calculate attention distribution\n",
        "        a = tf.nn.softmax(e, axis=1)\n",
        "\n",
        "        # Calculate the context vector\n",
        "        context_vector = tf.reduce_sum(a * h, axis=1)\n",
        "\n",
        "        return context_vector, a"
      ],
      "metadata": {
        "id": "MHR3Ol0X3H3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Tokenizer class\n",
        "tokenizer = Tokenizer()\n",
        "\n",
        "# Convert the corpus to token sequences\n",
        "token_sequences = tokenizer.texts_to_sequences(train_files)\n"
      ],
      "metadata": {
        "id": "kiFyxd4QYc_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import *\n",
        "\n",
        "# Pad the token sequences to ensure equal length\n",
        "max_sequence_length = max(len(seq) for seq in token_sequences) + 1  # Add 1 for the padding\n",
        "\n",
        "# Define the total number of words in the vocabulary\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Define the model architecture\n",
        "embedding_dim = 100\n",
        "decoder_units = 64\n",
        "attention_units = 10\n",
        "\n",
        "\n",
        "# Define the coverage loss weight\n",
        "lambda_val = 0.1\n",
        "\n",
        "encoder_model = Sequential([\n",
        "    Embedding(total_words, embedding_dim, input_length=max_sequence_length-1),\n",
        "    Bidirectional(LSTM(decoder_units, return_sequences=True)),\n",
        "    Dense(total_words, activation='softmax')\n",
        "])\n",
        "\n",
        "# Print the summary of the encoder model\n",
        "encoder_model.summary()\n",
        "\n",
        "decoder_model = Sequential([\n",
        "    Embedding(total_words, embedding_dim, input_length=max_sequence_length),\n",
        "    LSTM(decoder_units, return_sequences=True),\n",
        "    Dense(total_words, activation='softmax')\n",
        "])\n",
        "\n",
        "# Print the summary of the decoder model\n",
        "decoder_model.summary()\n",
        "\n",
        "# Define the coverage vector shape\n",
        "coverage_vector_shape = (max_sequence_length-1, total_words)\n",
        "\n",
        "# Define the coverage vector\n",
        "coverage_vector = tf.Variable(tf.zeros(coverage_vector_shape))\n",
        "\n",
        "# Calculate attention distribution\n",
        "context_vector = tf.zeros((1, decoder_units))  # Initial context vector\n",
        "attention_distributions = []\n",
        "\n",
        "for t in range(max_sequence_length - 1):\n",
        "    # Calculate attention distribution\n",
        "    attention_input = Concatenate(axis=-1)([decoder_model.output[:, t, :], context_vector, coverage_vector[t, :]])\n",
        "    attention_scores = Dense(1)(attention_input)\n",
        "    attention_scores = tf.squeeze(attention_scores, axis=-1)\n",
        "    attention_distribution = Activation('softmax')(attention_scores)\n",
        "    attention_distributions.append(attention_distribution)\n",
        "\n",
        "    # Update context vector\n",
        "    context_vector = tf.reduce_sum(tf.expand_dims(attention_distribution, axis=-1) * encoder_model.output, axis=1)\n",
        "\n",
        "# Calculate attention distribution\n",
        "attention = Dot(axes=[2, 2])([decoder_model.output, encoder_model.output])\n",
        "attention = Activation('softmax')(attention)\n",
        "\n",
        "# Calculate the coverage loss\n",
        "coverage_loss = tf.reduce_sum(tf.minimum(attention, coverage_vector), axis=1)\n",
        "coverage_loss = lambda_val * tf.reduce_sum(coverage_loss, axis=-1)\n",
        "\n",
        "# Calculate the context vector\n",
        "context_vector = Dot(axes=[2, 1])([attention, encoder_model.output])\n",
        "\n",
        "# Concatenate the context vector and decoder state\n",
        "decoder_combined_context = Concatenate(axis=-1)([context_vector, decoder_model.output])\n",
        "\n",
        "# Two dense layers to calculate the probability distribution over the vocabulary\n",
        "vocabulary_distribution = Dense(total_words, activation='softmax')(decoder_combined_context)\n",
        "probability_distribution = vocabulary_distribution / tf.reduce_sum(vocabulary_distribution, axis=-1, keepdims=True)\n",
        "# Define pgen as a learnable parameter\n",
        "pgen = Dense(1, activation='sigmoid')(decoder_combined_context)\n",
        "\n",
        "# Extended vocabulary distribution for OOV words and source document words\n",
        "extended_vocabulary_distribution = pgen * probability_distribution\n",
        "copy_distribution = (1 - pgen) * attention\n",
        "\n",
        "# Calculate the coverage loss\n",
        "coverage_loss = tf.reduce_sum(tf.minimum(attention, coverage_vector), axis=1)\n",
        "lambda_val = 0.1  # Hyper\n",
        "\n",
        "\n",
        "# Define the target word indices for each timestep\n",
        "target_word_indices = tf.keras.Input(shape=(max_sequence_length,), name='target_word_indices')\n",
        "\n",
        "# Calculate the loss for each timestep\n",
        "loss_per_timestep = sparse_categorical_crossentropy(target_word_indices, vocabulary_distribution)\n",
        "loss_per_timestep = tf.reduce_mean(loss_per_timestep, axis=-1)\n",
        "\n",
        "# Calculate the overall loss for the whole sequence\n",
        "loss = tf.reduce_mean(loss_per_timestep)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTg0Anjv2yQD",
        "outputId": "56048142-e939-46db-a078-9fd81280f5e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 100)         100       \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, None, 128)        84480     \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, None, 1)           129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 84,709\n",
            "Trainable params: 84,709\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 1, 100)            100       \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 1, 64)             42240     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1, 1)              65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42,405\n",
            "Trainable params: 42,405\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.minimum), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(0, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
            "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.math.minimum_1), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(0, 1) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_article_length = 400\n",
        "max_summary_length = 120"
      ],
      "metadata": {
        "id": "AbYjzRhj24Wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import nltk\n",
        "\n",
        "# Define the maximum sequence length\n",
        "max_sequence_length = 100\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def loss(targets, predictions):\n",
        "    # Ensure the shapes of targets and predictions are compatible\n",
        "    if predictions.shape.ndims > 2:\n",
        "        predictions = predictions[:, :, 0]\n",
        "\n",
        "    # Calculate the loss\n",
        "    loss_value = tf.reduce_mean(tf.square(targets - predictions))\n",
        "\n",
        "    return loss_value\n",
        "\n",
        "# Define the preprocess_encoder_inputs function\n",
        "def preprocess_encoder_inputs(contents):\n",
        "    encoder_inputs = []\n",
        "    for content in contents:\n",
        "        # Tokenize the content using NLTK\n",
        "        tokens = nltk.word_tokenize(content)\n",
        "\n",
        "        # Convert tokens to numerical representation using a tokenizer\n",
        "        sequences = tokenizer.texts_to_sequences([tokens])\n",
        "\n",
        "        # Flatten the sequence\n",
        "        flattened_sequence = [item for sublist in sequences for item in sublist]\n",
        "\n",
        "        # Append the flattened sequence to the encoder inputs list\n",
        "        encoder_inputs.append(flattened_sequence)\n",
        "\n",
        "    # Pad the encoder inputs to ensure a consistent sequence length\n",
        "    encoder_inputs = pad_sequences(encoder_inputs, maxlen=max_sequence_length, padding='pre')\n",
        "\n",
        "    return encoder_inputs\n",
        "\n",
        "def preprocess_decoder_inputs(contents):\n",
        "    decoder_inputs = []\n",
        "    for content in contents:\n",
        "        # Tokenize the content using NLTK\n",
        "        tokens = nltk.word_tokenize(content)\n",
        "\n",
        "        # Add the start-of-sequence token to the tokens\n",
        "        tokens = ['<sos>'] + tokens\n",
        "\n",
        "        # Convert tokens to numerical representation using a tokenizer\n",
        "        sequences = tokenizer.texts_to_sequences([tokens])\n",
        "\n",
        "        # Flatten the sequence\n",
        "        flattened_sequence = [item for sublist in sequences for item in sublist]\n",
        "\n",
        "        # Append the flattened sequence to the decoder inputs list\n",
        "        decoder_inputs.append(flattened_sequence)\n",
        "\n",
        "    # Pad the decoder inputs to ensure a consistent sequence length\n",
        "    decoder_inputs = pad_sequences(decoder_inputs, maxlen=max_sequence_length, padding='post')\n",
        "\n",
        "    return decoder_inputs\n",
        "\n",
        "\n",
        "def preprocess_target_word_indices(contents):\n",
        "    target_word_indices = []\n",
        "    for content in contents:\n",
        "        # Tokenize the content using NLTK\n",
        "        tokens = nltk.word_tokenize(content)\n",
        "\n",
        "        # Add the end-of-sequence token to the tokens\n",
        "        tokens = tokens + ['<eos>']\n",
        "\n",
        "        # Convert tokens to numerical representation using a tokenizer\n",
        "        sequences = tokenizer.texts_to_sequences([tokens])\n",
        "\n",
        "        # Flatten the sequence\n",
        "        flattened_sequence = [item for sublist in sequences for item in sublist]\n",
        "\n",
        "        # Append the flattened sequence to the target word indices list\n",
        "        target_word_indices.append(flattened_sequence)\n",
        "\n",
        "    # Pad the target word indices to ensure a consistent sequence length\n",
        "    target_word_indices = pad_sequences(target_word_indices, maxlen=max_sequence_length, padding='post')\n",
        "\n",
        "    return target_word_indices\n",
        "\n"
      ],
      "metadata": {
        "id": "AN4DFZvibhTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')  # Download the required NLTK data\n",
        "\n",
        "# Define the model\n",
        "model = tf.keras.Model(inputs=[encoder_model.input, decoder_model.input],\n",
        "                       outputs=[vocabulary_distribution, extended_vocabulary_distribution, copy_distribution])\n",
        "\n",
        "# Compile the model\n",
        "optimizer = tf.keras.optimizers.Adagrad(learning_rate=0.15, initial_accumulator_value=0.1)\n",
        "model.compile(optimizer='adagrad', loss=[loss, loss, loss])\n",
        "\n",
        "# Define the number of epochs\n",
        "num_epochs = 10\n",
        "\n",
        "# Define the early stopping criteria\n",
        "early_stopping_patience = 5\n",
        "no_improvement_count = 0\n",
        "best_loss = float('inf')\n",
        "\n",
        "# Initialize variables for accuracy calculation\n",
        "total_examples = 0\n",
        "total_correct_predictions = 0\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    # Perform training for each batch\n",
        "    for batch in train_files:\n",
        "        # Extract the inputs and targets\n",
        "        encoder_inputs = preprocess_encoder_inputs(batch)\n",
        "        decoder_inputs = preprocess_decoder_inputs(batch)\n",
        "        target_word_indices = preprocess_target_word_indices(batch)\n",
        "\n",
        "        # Perform a forward pass\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Get the model predictions\n",
        "            vocabulary_preds, extended_vocabulary_preds, copy_preds = model([encoder_inputs, decoder_inputs])\n",
        "\n",
        "            # Calculate the loss\n",
        "            loss_value = loss(target_word_indices, vocabulary_preds) + loss(target_word_indices, extended_vocabulary_preds) + loss(target_word_indices, copy_preds)\n",
        "\n",
        "        # Perform backpropagation\n",
        "        gradients = tape.gradient(loss_value, model.trainable_variables)\n",
        "        gradients, _ = tf.clip_by_global_norm(gradients, 2)  # Gradient clipping\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "        # Calculate the accuracy for the current batch\n",
        "        batch_predictions = tf.argmax(vocabulary_preds, axis=-1)\n",
        "        correct_predictions = tf.equal(batch_predictions, target_word_indices)\n",
        "        batch_accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
        "\n",
        "        # Update the total number of examples and correct predictions\n",
        "        total_examples += target_word_indices.shape[0]\n",
        "        total_correct_predictions += tf.reduce_sum(tf.cast(correct_predictions, tf.float32)).numpy()\n",
        "\n",
        "        # Print the training loss and accuracy for each batch\n",
        "        print(f\"Training loss: {loss_value:.4f} \")\n",
        "\n",
        "\n",
        "\n",
        "    # Perform validation\n",
        "    validation_loss = 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "    for batch in test_files:\n",
        "        # Extract the inputs and targets for validation\n",
        "        encoder_inputs_val = preprocess_encoder_inputs(batch)\n",
        "        decoder_inputs_val = preprocess_decoder_inputs(batch)\n",
        "        target_word_indices_val = preprocess_target_word_indices(batch)\n",
        "\n",
        "        # Perform a forward pass for validation\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Get the model predictions for validation\n",
        "            vocabulary_preds_val, extended_vocabulary_preds_val, copy_preds_val = model([encoder_inputs_val, decoder_inputs_val])\n",
        "\n",
        "            # Calculate the loss for validation\n",
        "            loss_value_val = loss(target_word_indices_val, vocabulary_preds_val) + loss(target_word_indices_val, extended_vocabulary_preds_val) + loss(target_word_indices_val, copy_preds_val)\n",
        "\n",
        "            # Accumulate the validation loss\n",
        "            validation_loss += loss_value_val.numpy()\n",
        "\n",
        "        num_batches += 1\n",
        "\n",
        "    # Calculate the average validation loss\n",
        "    validation_loss /= num_batches\n",
        "    print(f\"Validation loss: {validation_loss:.4f}\")\n",
        "\n",
        "\n",
        "    # Check for early stopping\n",
        "    if validation_loss < best_loss:\n",
        "        best_loss = validation_loss\n",
        "        no_improvement_count = 0\n",
        "    else:\n",
        "        no_improvement_count += 1\n",
        "\n",
        "    # Early stopping condition\n",
        "    if no_improvement_count >= early_stopping_patience:\n",
        "        print(\"Early stopping. No improvement in validation loss.\")\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWMvKcBZF2Vj",
        "outputId": "f0259a15-36c0-45b9-de76-4ab7637aa7f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 1.0527 \n",
            "Validation loss: 1.0443\n",
            "Training loss: 1.0443 \n",
            "Validation loss: 1.0381\n",
            "Training loss: 1.0381 \n",
            "Validation loss: 1.0334\n",
            "Training loss: 1.0334 \n",
            "Validation loss: 1.0297\n",
            "Training loss: 1.0297 \n",
            "Validation loss: 1.0267\n",
            "Training loss: 1.0267 \n",
            "Validation loss: 1.0243\n",
            "Training loss: 1.0243 \n",
            "Validation loss: 1.0222\n",
            "Training loss: 1.0222 \n",
            "Validation loss: 1.0205\n",
            "Training loss: 1.0205 \n",
            "Validation loss: 1.0190\n",
            "Training loss: 1.0190 \n",
            "Validation loss: 1.0177\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install rouge"
      ],
      "metadata": {
        "id": "zyrsQMAWF2Yh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17e2355e-b79c-450f-a7e4-297753010c4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge) (1.16.0)\n",
            "Installing collected packages: rouge\n",
            "Successfully installed rouge-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from rouge import Rouge\n",
        "\n",
        "# Example reference and generated summaries\n",
        "reference_texts = [\"The estranged wife of former football star Deion Sanders was released from custody Tuesday in suburban Dallas and said she hasn't been given a fair shake over allegations that she attacked him \\n.\"\n",
        "\n",
        "\"Pilar Sanders was arrested on domestic violence-related charges Monday night, hours after Sanders sent a series of bizarre tweets saying she assaulted him \\n.\"\n",
        "\n",
        "\"I understand that I have very little chance at beating a Hall of Fame, two-sport man that everyone seems to love and adore, said Pilar Sanders, proclaiming her innocence \\n.\"\n",
        "\n",
        "\"I'm a full-time mom, 100% for my children, she said tearfully. And I just haven't been given a fair shake. \\n\"\n",
        "\n",
        "\"The Collin County Sheriff's Office said Pilar Sanders, under an emergency protective order, is forbidden from returning to the couple's home for 61 days and cannot threaten or harass any member of the family \\n.\"\n",
        "\n",
        "\"In one of the messages posted on his verified Twitter account, Deion Sanders posted a picture of what he said were his children filling out complaints to give to police in Texas \\n.\"\n",
        "\n",
        "\"Pray for me and my kids now! They just witnessed their mother and a friend jump me in my room, the first tweet, posted at 6:15 p.m., read. She's going to jail n I'm pressing charges! \\n\"\n",
        "\n",
        "\"Two minutes later, Sanders tweeted again \\n.\"\n",
        "\n",
        "\"I'm sad my boys witnessed this mess but I warned the police department here that she was gone try n harm me and my boys. This is on my mama! it said \\n.\"\n",
        "\n",
        "\"Shortly after that, Sanders tweeted a picture that showed him and his two boys, 10 and 12, filling out paperwork \\n.\"\n",
        "\n",
        "\"Filling out police reports now! Thank God for this platform to issue the Truth,the caption read \\n.\"\n",
        "\n",
        "\"Pilar Sanders was booked into jail Monday night on suspicion of assault family violence, a misdemeanor, according to booking records at the Collin County Jail. Bail was set at $264 \\n.\"\n",
        "\n",
        "\"I can tell you that there are two sides to every story, and the truth will come out in court, Larry Friedman, an attorney for Pilar Sanders, said Tuesday \\n.\"\n",
        "\n",
        "\"Deion Sanders played for several NFL teams, including the San Francisco 49ers, the Dallas Cowboys and the Atlanta Falcons. He was inducted into the NFL Hall of Fame and works as an analyst for the NFL Network.\\n\"\n",
        "\"During much of his NFL career, he also was an outfielder with four Major League Baseball teams and played in a World Series with the Atlanta Braves \\n.\"\n",
        "\n",
        "\"The NFL Network and Sanders' business manager, Constance Schwartz, declined to comment about the incident.\\n\"\n",
        "\n",
        "\"But a clearly emotional Sanders spoke to Dallas television station KXAS on Monday night and appealed for help\\n.\"\n",
        "\n",
        "\"My kids, they are scared for their life, Sanders told the station. They just saw two women jump their dad in his own house, in his room, in my room. It's sad \\n.\"\n",
        "\n",
        "\"I got locks on my doors right now,he added. Is somebody going to have to die? Is it going to be me before the court does something and get this woman out of my house? It's absurd.\\n\"\n",
        "\n",
        "\"The couple has three children together. Sanders has two other children from an earlier relationship.\\n\"\n",
        "\n",
        "\"The couple married in 1999 and starred in a reality show, Deion & Pilar Prime Time Love, that aired on the Oxygen network. The marriage, soured, however, and the two are in the midst of a bitter divorce \\n.\"\n",
        "\n",
        "\"In February, Pilar Sanders filed a suit against her husband and his aunt, Laura Jones. She said the aunt attacked her in their 10-bedroom, 29,000-square-foot home in Prosper, Texas, while Deion Sanders watched \\n.\"\n",
        "\n",
        "\"At the time, the athlete tweeted that his wife was the aggressor and the aunt was in the home merely to fix his phone \\n.\"\n",
        "\n",
        "\"Pilar Sanders also filed a separate suit against her husband and his daughter, Deiondra, after she called her stepmother a gold-digging (expletive) and the number one gold digger of the year in Twitter posts \\n.\"\n",
        "\n",
        "\"In the second suit, Pilar Sanders demanded $200 million in damages for libelous and slanderous comments. She claims that her husband endorsed Deiondras false statements and himself tweeted he was tired of all Pilars lies and foolishness.\\n\"\n",
        "]\n",
        "\n",
        "\n",
        "####################\n",
        "generated_texts = [\"Buddy Holly finally got his star on Hollywoods Walk of Fame on Wednesday, which would have been the singer-songwriters 75th birthday \\n.\"\n",
        "\n",
        "\"Its never too late when you get a fantastic thing to happen, his widow, Maria Elena Holly, told CNN after unveiling the star on the sidewalk along Vine Street at the entrance to the historic Capitol Records building \\n.\"\n",
        "\n",
        "\"Holly was just 22 when he was killed in a plane crash, along with musicians Ritchie Valens and J.P. The Big Bopper Richardson \\n.\"\n",
        "\n",
        "\"Im saying now, my dear Buddy, you loved to go to the movies. You told me that one of your dreams was to write scores for movies and make your mark in Hollywood, his widow said during the ceremony. Well, my dear, half of your dream unfortunately did not come true, but the other half did come true with a beautiful star on the Hollywood Walk of Fame. \\n\"\n",
        "\n",
        "\"Actor Gary Busey, who channeled Holly's voice and character in the 1978 movie The Buddy Holly Story, attended the dedication.\\n\"\n",
        "\n",
        "\"Hes here right now, Busey said. I feel his spirit in the air. It's beautiful.\"\n",
        "\n",
        "\"What would Holly be doing now if he were still alive?\\n\"\n",
        "\n",
        "\"Anything he wanted to, Busey said. Scoring movies, helping people in different countries who are in trouble, like writing a song for them and taking it over there and singing it to them.\\n\"\n",
        "\n",
        "\"Busey is working with T Bone Burnett on an album of Holly songs, which he said he would also perform in a tour\\n.\"\n",
        "\n",
        "\"The Hollywood star ceremony was timed to coincide with this week's release of Listen to Me: Buddy Holly, a tribute album of his songs performed by 16 artists, including Ringo Starr, Stevie Nick, Brian Wilson, Jackson Browne, Chris Isaak, Linda Ronstadt and Lyle Lovett.\\n\"\n",
        "\n",
        "\"Phil Everly of the Everly Brothers, a contemporary of Holly, also attended the dedication.\"]\n",
        "\n",
        "# Initialize the ROUGE scorer\n",
        "rouge = Rouge()\n",
        "\n",
        "# Calculate ROUGE scores\n",
        "scores = rouge.get_scores(generated_texts, reference_texts, avg=True)\n",
        "\n",
        "# Print ROUGE scores\n",
        "print(\"ROUGE scores:\")\n",
        "print(f\"ROUGE-1: {scores['rouge-1']}\")\n",
        "print(f\"ROUGE-2: {scores['rouge-2']}\")\n",
        "print(f\"ROUGE-L: {scores['rouge-l']}\")"
      ],
      "metadata": {
        "id": "X3oqgAS5TsNw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a662553-142c-419d-f2d3-bf0373c9aea8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROUGE scores:\n",
            "ROUGE-1: {'r': 0.12903225806451613, 'p': 0.23880597014925373, 'f': 0.16753926246100723}\n",
            "ROUGE-2: {'r': 0.01889763779527559, 'p': 0.04054054054054054, 'f': 0.025778728208584182}\n",
            "ROUGE-L: {'r': 0.12365591397849462, 'p': 0.22885572139303484, 'f': 0.16055845966868612}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Om794IJJQTak"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}